{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdff7FhW8h6bLyG1IgwtSx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Cleaning Raw Data (Without Regex Pattern)"],"metadata":{"id":"FDf2XqWLy3YW"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJDLXxhSVAIW","executionInfo":{"status":"ok","timestamp":1751026303483,"user_tz":-480,"elapsed":32,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"97081645-f837-47ca-9345-47f3b087461e"},"outputs":[{"output_type":"stream","name":"stdout","text":["the quick brown fox jumps over the lazy dog!!!\n"]}],"source":["import re\n","\n","noised_text = \"teh qwik brwon fx jmps ovr teh lazi dag!!!\"\n","\n","def preprocessing_step(text):\n","  text = text.lower() # lowercase all senctences\n","  text = re.sub('teh', 'the', text)\n","  text = re.sub('dag','dog', text)\n","  text = re.sub('qwik', 'quick', text)\n","  text = re.sub('jmps', 'jumps', text)\n","  text = re.sub('brwon', 'brown', text)\n","  text = re.sub('lazi', 'lazy', text)\n","  text = re.sub('fx', 'fox', text)\n","  text = re.sub('ovr', 'over', text)\n","  return text\n","\n","print(preprocessing_step(noised_text))\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b952a954","executionInfo":{"status":"ok","timestamp":1751026303526,"user_tz":-480,"elapsed":44,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"06a950c5-fb23-46b4-fac4-b6c5088288bb"},"source":["# 1. The quick brown fox jumps over the lazy dog\n","noised_text = \"teh qwik brwon fx jmps ovr teh lazi dag!!!\"\n","\n","# Preprocessing\n","def preprocessing_step_optimized(text):\n","    text = text.lower()\n","    replacements = {\n","        'teh': 'the',\n","        'dag': 'dog',\n","        'qwik': 'quick',\n","        'jmps': 'jumps',\n","        'brwon': 'brown',\n","        'lazi': 'lazy',\n","        'fx': 'fox',\n","        'ovr': 'over'\n","    }\n","    # Use a regex pattern to find words and replace them if in the replacements dictionary\n","    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in replacements.keys()) + r')\\b')\n","    text = pattern.sub(lambda x: replacements[x.group(0)], text)\n","    return text\n","\n","print(preprocessing_step_optimized(noised_text))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["the quick brown fox jumps over the lazy dog!!!\n"]}]},{"cell_type":"code","source":["# using regex pattern\n","raw_text = \"D@ta prepr0cessing iz essenntial 4 accurte NLP modls\"\n","\n","#2. Data preprocessing is essential for accurate NLP models.\n","\n","\n","# Preprocessing\n","def clean_text_with_regex(text):\n","  text = text.lower()\n","  reg = r\"[^a-zA-Z\\s]\"\n","  cleaned_text = re.sub(reg, '', text)\n","  replacement = {\n","      \"dta\":'data',\n","      \"preprcessing\":'preprocessing',\n","      \"essenntial\":'essential',\n","      \"accurte\":'accurate',\n","      \"modls\":'models',\n","      'iz': 'is'\n","  }\n","\n","  pattern = re.compile(r'\\b('+ '|'.join(re.escape(key) for key in replacement.keys())+ r')\\b')\n","  cleaned_text = pattern.sub(lambda x: replacement[x.group(0)], cleaned_text)\n","  cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n","  return cleaned_text\n","\n","clean_text_with_regex(raw_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"6wQx3NPhAXLU","executionInfo":{"status":"ok","timestamp":1751026303600,"user_tz":-480,"elapsed":76,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"2bedb925-7cf5-4d44-a637-4d8ec9fd28dc"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'data preprocessing is essential accurate nlp models'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4a897ad","executionInfo":{"status":"ok","timestamp":1751026303603,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"b3111972-a3ef-4b36-af0e-2e8748092ba0"},"source":["#3. He couldn’t believe how effective the algorithm was.\n","raw_text = \"He cudnt beleev how effctiv the algorithem wuz\"\n","\n","# Preprocessing\n","def prep_step(txt):\n","  txt = txt.lower()\n","  replacement = {\n","      'cudnt': 'could not',\n","      'effctiv': 'effective',\n","      'algorithem': 'algorithm',\n","      'wuz': 'was',\n","      'beleev': 'believe'\n","  }\n","  pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in replacement.keys()) + r')\\b')\n","  txt = pattern.sub(lambda x: replacement[x.group(0)], txt)\n","  return txt\n","\n","cleaned_text3 = prep_step(raw_text)\n","print(cleaned_text3)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["he could not believe how effective the algorithm was\n"]}]},{"cell_type":"code","source":["#4. Natural language understanding is a core task in AI.\n","raw_text =  \"Naturall lngg understanting's a coor tazk in AI\"\n","\n","# Preprocessing\n","def clean_text(text):\n","  text = text.lower()\n","  replacement = {\n","      'Naturall':'Natural',\n","      'lngg': 'language',\n","      \"understanting's\": 'understanding is',\n","      'coor': 'core',\n","      'tazk': 'task'\n","  }\n","  pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in replacement.keys()) + r')\\b')\n","  text = pattern.sub(lambda x: replacement[x.group(0)], text)\n","  return text\n","\n","clean_text4 = clean_text(raw_text)"],"metadata":{"id":"ydNRKWCfvgt7","executionInfo":{"status":"ok","timestamp":1751026303605,"user_tz":-480,"elapsed":8,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#5. Tokenization splits text into smaller units for analysis.\n","\n","raw_text = 'Tokenisashun spl1tz txt into smoller unitts fr analysys'\n","\n","# Preprocessing\n","def clean_text(text):\n","  text = text.lower()\n","  replacement = {\n","      'tokenisashun': 'tokenization',\n","      'spl1tz': 'splits',\n","      'txt': 'text',\n","      'into': 'for',\n","      'smoller': 'smaller',\n","      'unitts': 'units',\n","      'fr': 'for',\n","      'analysys': 'analysis'\n","  }\n","\n","  pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in replacement.keys())+r')\\b')\n","  text = pattern.sub(lambda x: replacement[x.group(0)], text)\n","  return text\n","\n","clean_text5 = clean_text(raw_text)"],"metadata":{"id":"fi755otHwhnU","executionInfo":{"status":"ok","timestamp":1751026303609,"user_tz":-480,"elapsed":3,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Using Regex Pattern"],"metadata":{"id":"CG-He3WjyypY"}},{"cell_type":"code","source":["# Focus: Remove non-alphabetic characters, preserve meaningful tokens.\n","raw_data ='@rguments%%can-b-#illogical...!!'\n","reg = '[^\\w\\s+]'\n","replacement = {\n","    'rguments' : 'arguments',\n","    'b': 'be'\n","}\n","\n","clean_txt = re.sub(reg, ' ', raw_data)\n","pattern = re.compile(r'\\b(' + \"|\".join(re.escape(key) for key in replacement.keys()) + r')\\b')\n","clean_txt = pattern.sub(lambda x: replacement[x.group(0)], clean_txt)\n","print(clean_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsWnsH9exS8i","executionInfo":{"status":"ok","timestamp":1751026432389,"user_tz":-480,"elapsed":12,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"b39f1c99-6cd8-4ce2-80aa-ead73a7e6d3e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":[" arguments  can be  illogical     \n"]}]},{"cell_type":"code","source":["# Word correction via \\b() groups and replacements.\n","raw_data = 'Speling missteaks izz nott alweys obvius'\n","replacement = {\n","    'missteaks': 'mistakes',\n","    'izz': 'is',\n","    'alweys': 'always',\n","    'nott': 'not',\n","    'Speling':'Spelling'\n","}\n","pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in replacement.keys()) + r')\\b')\n","clean_txt = pattern.sub(lambda x: replacement[x.group(0)], raw_data)\n","print(clean_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aOWvTqtzDP0","executionInfo":{"status":"ok","timestamp":1751027144445,"user_tz":-480,"elapsed":18,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"2ced2080-3b40-47ee-ae54-5c361175f911"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Spelling misspelling is not always obvius\n"]}]},{"cell_type":"code","source":["# Detect and reduce excessive character repetition (hint: (.)\\1{2,}).\n","raw_data = 'Repetitionnnnn issssss an errrrorrrr...'\n","regex = r'(.)\\1{2,}'\n","clean_data = re.sub(regex, r'\\1', raw_data)\n","print(clean_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YeyklFgWdU3","executionInfo":{"status":"ok","timestamp":1751027679945,"user_tz":-480,"elapsed":11,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"53ac3cc4-923d-45dd-82c8-c123deaf145c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Repetition is an eror.\n"]}]},{"cell_type":"code","source":["# Extract words amidst numbers/underscores using \\w, \\d, and boundaries.\n","raw_data = '123Repl4ce_th3nClean567!'\n","regex = r'\\w+'\n","clean_data = re.sub(regex, 'Replace then Clean', raw_data)\n","print(clean_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5muR0BAWYLJx","executionInfo":{"status":"ok","timestamp":1751029840033,"user_tz":-480,"elapsed":56,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"1c9a4cec-a53a-4c63-d9c5-19448e382504"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Replace then Clean!\n"]}]},{"cell_type":"code","source":["# Smart tokenization—preserve underscores in named entities, split on dashes/punctuation elsewhere.\n","raw_data = 'do_not-split_me.but-split_this one'\n","regex = r'\\W+'\n","clean_data = re.sub(regex, ' ', raw_data)\n","print(clean_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RgpS8EjSgjph","executionInfo":{"status":"ok","timestamp":1751032659376,"user_tz":-480,"elapsed":20,"user":{"displayName":"Fikri Abdillah","userId":"15227818917415993484"}},"outputId":"de4a3232-ba02-4f04-80cd-626859440679"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["do_not split_me but split_this one\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yYuc5VC-g_s_"},"execution_count":null,"outputs":[]}]}